import subprocess
import time
import json
import requests
from flask import Flask, request, render_template, jsonify, send_file, Response
import os
import traceback
import uuid
import queue
import torch
import sys
import shutil
import pickle
from flask import send_from_directory
from urllib.parse import unquote
sys.path.append(os.path.dirname(__file__))
from ä¸‹è½½ import (
    identify_platform,
    download_video_by_url,
    ROOT_DOWNLOAD_DIR as CRAWLER_ROOT_DIR,
    create_dir,
    safe_filename
)
from analyze_GLM import GLM_Vision_API, GLM_API_KEY
#from frame_extractor_v2 import extract_frames_to_queue
from smart_frame_extractor import extract_frames_to_queue, SamplingStrategy
from model_inferencer import infer_batch_from_memory
from risk_judger import (
    is_frame_risky,
    calculate_risk_level,
    calculate_risk_score,
    generate_risk_details
)
import numpy as np
import cv2
import base64
from datetime import datetime

# ========== æŒä¹…åŒ–è§†é¢‘ç¼“å­˜é…ç½® ==========
VIDEO_CACHE_FILE = os.path.join(os.path.dirname(__file__), "video_cache.pkl")
def save_video_cache():
    with open(VIDEO_CACHE_FILE, 'wb') as f:
        pickle.dump(uploaded_videos, f)
def load_video_cache():
    if os.path.exists(VIDEO_CACHE_FILE):
        with open(VIDEO_CACHE_FILE, 'rb') as f:
            return pickle.load(f)
    return {}

# ========== çˆ¬è™«é…ç½® ==========
CRAWLER_DOWNLOAD_DIR = os.path.join(os.path.dirname(__file__), 'static', 'crawler_downloads')
import ä¸‹è½½
ä¸‹è½½.ROOT_DOWNLOAD_DIR = CRAWLER_DOWNLOAD_DIR
create_dir(CRAWLER_DOWNLOAD_DIR)

FFMPEG_PATH = "C:\\Users\\86187\\Desktop\\ffmpeg-7.1-essentials_build\\bin"
os.environ["PATH"] = FFMPEG_PATH + ";" + os.environ["PATH"]
cv2.ocl.setUseOpenCL(False)
cv2.setNumThreads(1)

app = Flask(__name__, template_folder='.', static_folder='static')

# ========== å…¨å±€å˜é‡ ==========
uploaded_videos = load_video_cache()
device_info = {}
performance_benchmark = {}
_BATCH_SIZE = 8
_HEARTBEAT_INTERVAL = 2.0

# ========== å…³é”®é…ç½® ==========
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
app.config['TEMPLATES_AUTO_RELOAD'] = True
FEEDBACK_DIR = os.path.join(os.path.dirname(__file__), "feedbacks")
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024

def initialize_system():
    global device_info
    device_info = {
        "cuda_available": torch.cuda.is_available(),
        "cuda_device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "cuda_devices": [],
        "pytorch_version": torch.__version__,
        "system_info": {
            "platform": os.name,
            "python_version": os.sys.version.split()[0],
            "processor": os.environ.get('PROCESSOR_IDENTIFIER', 'Unknown')
        }
    }
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            device_info["cuda_devices"].append({
                "id": i,
                "name": torch.cuda.get_device_name(i),
                "capability": torch.cuda.get_device_capability(i),
                "total_memory_mb": round(torch.cuda.get_device_properties(i).total_memory / 1024 ** 2, 2)
            })
    os.makedirs(FEEDBACK_DIR, exist_ok=True)
    os.makedirs(CRAWLER_DOWNLOAD_DIR, exist_ok=True)
    os.makedirs(os.path.join(os.path.dirname(__file__), 'static', 'downloaded'), exist_ok=True)

def is_platform_video_url(url: str) -> bool:
    return identify_platform(url) is not None

def is_direct_mp4_url(url: str) -> bool:
    return url.lower().endswith('.mp4') and ('http' in url.lower())

def download_video_from_url(video_url: str, output_dir: str) -> str:
    os.makedirs(output_dir, exist_ok=True)
    video_id = str(uuid.uuid4())
    if is_platform_video_url(video_url):
        print(f"â¬‡ï¸ è¯†åˆ«ä¸ºçŸ­è§†é¢‘URLï¼Œè°ƒç”¨çˆ¬è™«ä¸‹è½½: {video_url}")
        try:
            download_video_by_url(video_url)
        except Exception as e:
            print(f"çˆ¬è™«è°ƒç”¨å¼‚å¸¸: {str(e)}")
        platform = identify_platform(video_url)
        if not platform:
            raise RuntimeError(f"æ— æ³•è¯†åˆ«URLæ‰€å±å¹³å°: {video_url}")
        platform_dir = os.path.join(CRAWLER_DOWNLOAD_DIR, platform)
        if not os.path.exists(platform_dir):
            raise RuntimeError(f"çˆ¬è™«å¹³å°ç›®å½•ä¸å­˜åœ¨: {platform_dir}")
        video_files = [f for f in os.listdir(platform_dir) if f.lower().endswith('.mp4')]
        if not video_files:
            raise RuntimeError(f"å¹³å°ç›®å½•ä¸‹æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {platform_dir}")
        video_files.sort(key=lambda x: os.path.getmtime(os.path.join(platform_dir, x)), reverse=True)
        crawler_video_path = os.path.join(platform_dir, video_files[0])
        safe_name = safe_filename(f"{platform}_{video_id}")
        output_path = os.path.join(output_dir, f"{safe_name}.mp4")
        shutil.copy2(crawler_video_path, output_path)
        print(f"âœ… çŸ­è§†é¢‘ä¸‹è½½å®Œæˆ: {output_path}")
        return output_path
    elif is_direct_mp4_url(video_url):
        print(f"â¬‡ï¸ è¯†åˆ«ä¸ºMP4ç›´é“¾ï¼Œç›´æ¥ä¸‹è½½: {video_url}")
        output_path = os.path.join(output_dir, f"{video_id}.mp4")
        resp = requests.get(video_url, stream=True, timeout=30)
        resp.raise_for_status()
        with open(output_path, 'wb') as f:
            for chunk in resp.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        if not os.path.exists(output_path) or os.path.getsize(output_path) < 1024 * 50:
            raise RuntimeError("MP4ç›´é“¾ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æˆ–è¿‡å°")
        print(f"âœ… MP4ç›´é“¾ä¸‹è½½å®Œæˆ: {output_path}")
        return output_path
    else:
        raise RuntimeError(f"ä¸æ”¯æŒçš„URLç±»å‹: {video_url}")

@app.after_request
def add_header(response):
    response.headers['X-Accel-Buffering'] = 'no'
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    response.headers['Connection'] = 'keep-alive'
    response.headers['X-SSE-Ping-Interval'] = '2000'
    return response

# ========== ç›®å½•é…ç½® ==========
STATIC_DIR = os.path.join(os.path.dirname(__file__), 'static')
os.makedirs(STATIC_DIR, exist_ok=True, mode=0o777)

# ========== æ¥å£ ==========
@app.route('/describe-frame', methods=['POST'])
def describe_frame():
    try:
        data = request.get_json()
        if not data or 'image_base64' not in data:
            return jsonify({"success": False,"description": "","error": "ç¼ºå°‘å›¾ç‰‡Base64æ•°æ®"}), 400
        glm_api = GLM_Vision_API(GLM_API_KEY)
        prompt = data.get('prompt',"è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ï¼ŒåŒ…æ‹¬äººç‰©ã€åœºæ™¯ã€åŠ¨ä½œã€æ°›å›´ç­‰")
        result = glm_api.describe_image_base64(data['image_base64'], prompt)
        return jsonify(result)
    except Exception as e:
        traceback.print_exc()
        return jsonify({"success": False,"description": "","error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500

@app.route('/')
def index():
    return render_template('index.html')

def frame_to_base64(frame_array):
    try:
        if frame_array is None or frame_array.size == 0:
            return None
        if frame_array.dtype != np.uint8:
            frame_array = frame_array.astype(np.uint8)
        encode_param = [cv2.IMWRITE_JPEG_QUALITY, 80]
        retval, buffer = cv2.imencode('.jpg', frame_array, encode_param)
        if not retval:
            return None
        base64_str = base64.b64encode(buffer).decode('utf-8')
        return base64_str
    except Exception as e:
        print(f"âŒ å¸§è½¬Base64å¤±è´¥: {e}")
        return None

def process_batch(batch_cache, batch_indices, batch_arrays, batch_count, total_infer_time, device_info):
    if not batch_cache:
        return [], 0, batch_count, total_infer_time
    print(f"ğŸš€ å¼€å§‹ç¬¬{batch_count + 1}æ‰¹æ¬¡æ¨ç†ï¼Œå¤§å°: {len(batch_cache)}")
    infer_start = time.time()
    batch_results = infer_batch_from_memory(batch_cache)
    infer_time = time.time() - infer_start
    batch_count += 1
    total_infer_time += infer_time
    frame_results = []
    if batch_results and len(batch_results) == len(batch_cache):
        for i, result in enumerate(batch_results):
            if i >= len(batch_indices):
                continue
            frame_idx = batch_indices[i]
            frame_array = batch_arrays[i]
            horror = float(result.get('horror', 0))
            violence = float(result.get('violence', 0))
            nsfw = float(result.get('nsfw', 0))
            is_risk = bool(is_frame_risky(result))
            performance_data = result.get('performance', {})
            frame_base64 = frame_to_base64(frame_array)
            if frame_base64:
                frame_data = {
                    'frame_base64': frame_base64,
                    'frame_index': frame_idx,
                    'horror': horror,
                    'violence': violence,
                    'nsfw': nsfw,
                    'is_risk': is_risk,
                    'single_frame_duration': performance_data.get('total_infer_time_ms', 0) / 1000,
                    'performance_stats': {
                        'frame_idx': frame_idx,
                        'batch_size': len(batch_cache),
                        'batch_index': batch_count,
                        'preprocess_time_ms': performance_data.get('preprocess_time_ms', 0),
                        'total_infer_time_ms': performance_data.get('total_infer_time_ms', 0),
                        'fps': performance_data.get('fps', 0),
                        'device': device_info['cuda_devices'][0]['name'] if device_info['cuda_available'] else 'CPU',
                        'mode': 'batch'
                    }
                }
                frame_results.append({
                    'data': frame_data,
                    'idx': frame_idx,
                    'scores': {'horror': horror,'violence': violence,'nsfw': nsfw,'is_risk': is_risk,'single_frame_duration': performance_data.get('total_infer_time_ms',0)/1000}
                })
    else:
        print(f"âš ï¸ ç¬¬{batch_count}æ‰¹æ¬¡æ¨ç†ç»“æœå¼‚å¸¸")
    return frame_results, infer_time, batch_count, total_infer_time

def send_heartbeat():
    return f": heartbeat {datetime.now().timestamp()}\n\n"

@app.route('/upload', methods=['POST'])
def upload_video():
    try:
        content_type = request.headers.get('Content-Type', '')
        if content_type.startswith('application/json'):
            data = request.get_json(silent=True) or {}
            video_url = data.get('video_url', '').strip()
            if not video_url:
                return jsonify({'success': False, 'message': 'ç¼ºå°‘ video_url'})
            video_id = str(uuid.uuid4())
            download_dir = os.path.join(STATIC_DIR, 'downloaded')
            os.makedirs(download_dir, exist_ok=True)
            local_video_path = download_video_from_url(video_url,output_dir=download_dir)
            public_url = f"/static/downloaded/{os.path.basename(local_video_path)}"
            uploaded_videos[video_id] = {
                'source': 'url',
                'video_source': video_url,
                'path': local_video_path,
                'original_name': os.path.basename(local_video_path),
                'url': public_url
            }
            save_video_cache()
            return jsonify({'success': True,'video_id': video_id,'video_url': public_url,'message': 'è§†é¢‘å·²è§£æå®Œæˆ'})
        elif content_type.startswith('multipart/form-data'):
            if 'video' not in request.files:
                return jsonify({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©è§†é¢‘æ–‡ä»¶'})
            file = request.files['video']
            if not file or file.filename == '':
                return jsonify({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©è§†é¢‘æ–‡ä»¶'})
            video_id = str(uuid.uuid4())
            original_filename = file.filename
            safe_filename_str = original_filename.replace('/', '_').replace('\\', '_').replace(':', '_')
            video_filename = f"{video_id}_{safe_filename_str}"
            video_path = os.path.join(STATIC_DIR, video_filename)
            file.save(video_path)
            public_url = f"/static/{video_filename}"
            uploaded_videos[video_id] = {
                'source': 'local',
                'video_source': video_path,
                'path': video_path,
                'original_name': original_filename,
                'url': public_url
            }
            save_video_cache()
            return jsonify({'success': True,'video_id': video_id,'video_url': public_url,'message': 'è§†é¢‘ä¸Šä¼ æˆåŠŸ'})
        else:
            return jsonify({'success': False, 'message': 'ä¸æ”¯æŒçš„è¯·æ±‚æ ¼å¼'})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False,'message': f'ä¸Šä¼ å¤±è´¥ï¼š{str(e)}'})
# ========== ä¿®å¤ï¼šget-video-info æ¥å£ï¼ˆå¯¹é½äººå·¥å®¡æ ¸å­—æ®µï¼‰ ==========
@app.route('/get-video-info')
def get_video_info():
    try:
        video_id = request.args.get('video_id')
        if not video_id:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘video_idå‚æ•°'})
        if video_id not in uploaded_videos:
            return jsonify({'success': False, 'message': 'è§†é¢‘IDä¸å­˜åœ¨'})

        # æ ¸å¿ƒï¼šè·å–äººå·¥å®¡æ ¸ç»“æœï¼Œå¯¹é½å­˜å…¥çš„å­—æ®µå
        re_audit_data = uploaded_videos[video_id].get('re_audit_result', {})

        video_info = {
            'video_id': video_id,
            'original_name': uploaded_videos[video_id]['original_name'],
            'url': uploaded_videos[video_id]['url'],
            'source': uploaded_videos[video_id]['source'],
            'analysis_result': uploaded_videos[video_id].get('analysis_result', {}),
            # ========== ä¿®å¤ï¼šå­—æ®µåä¸submit_re_auditå¯¹é½ ==========
            're_audit_result': {
                'status': re_audit_data.get('status', 'none'),  # å®¡æ ¸çŠ¶æ€
                'risk_level': re_audit_data.get('re_audit_level', ''),  # é£é™©ç­‰çº§
                'desc': re_audit_data.get('re_audit_desc', 'æš‚æ— äººå·¥å®¡æ ¸'),  # å®¡æ ¸è¯´æ˜
                'audit_time': re_audit_data.get('re_audit_time', 'æš‚æ— ')  # å®¡æ ¸æ—¶é—´
            }
        }
        return jsonify({'success': True, 'video_info': video_info})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'è·å–è§†é¢‘å¤±è´¥ï¼š{str(e)}'})


# ========== ä¿æŒï¼šsubmit_re_audit æ¥å£ï¼ˆç¡®ä¿å­˜å…¥å­—æ®µæ­£ç¡®ï¼‰ ==========
@app.route('/submit-re-audit', methods=['POST'])
def submit_re_audit():
    try:
        data = request.get_json()
        feedback_id = data.get("feedback_id")
        re_audit_data = data.get("re_audit_data")
        if not feedback_id or not re_audit_data:
            return jsonify({"success": False, "message": "å‚æ•°é”™è¯¯"}), 400
        feedback_file = os.path.join(FEEDBACK_DIR, f"{feedback_id}.json")
        if not os.path.exists(feedback_file):
            return jsonify({"success": False, "message": "åé¦ˆè®°å½•ä¸å­˜åœ¨"}), 404
        with open(feedback_file, "r+", encoding="utf-8") as f:
            feedback = json.load(f)
            feedback.update(re_audit_data)
            f.seek(0)
            json.dump(feedback, f, ensure_ascii=False, indent=2)
            f.truncate()

        # ========== åŒæ­¥äººå·¥å®¡æ ¸ç»“æœåˆ°è§†é¢‘ç¼“å­˜ ==========
        video_id = feedback.get('video_id')
        if video_id and video_id in uploaded_videos:
            # å­˜å…¥çš„å­—æ®µåï¼šre_audit_level/re_audit_desc/re_audit_timeï¼ˆä¸get-video-infoå¯¹é½ï¼‰
            uploaded_videos[video_id]['re_audit_result'] = re_audit_data
            save_video_cache()  # æŒä¹…åŒ–ç¼“å­˜
            print(f"âœ… äººå·¥å®¡æ ¸ç»“æœå·²åŒæ­¥åˆ°è§†é¢‘ç¼“å­˜ (video_id: {video_id})")

        return jsonify({"success": True})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"success": False, "message": f"å®¡æ ¸æäº¤å¤±è´¥ï¼š{str(e)}"}), 500

@app.route('/analyze-sse')
def analyze_sse():
    video_id = request.args.get('video_id')
    if not video_id or video_id not in uploaded_videos:
        return Response(json.dumps({'message': 'æ— æ•ˆçš„è§†é¢‘ID'}), mimetype='text/event-stream', status=400)

    def generate_sse():
        last_heartbeat = time.time()
        connection_active = True
        error_occurred = False
        try:
            total_start_time = time.time()
            video_info = uploaded_videos[video_id]
            video_path = video_info['path']
            print(f"ğŸ“Œ å¼€å§‹åˆ†æè§†é¢‘: {video_path}")
            yield f"event: connection\ndata: {json.dumps({'status': 'connected', 'message': 'SSEè¿æ¥å·²å»ºç«‹'}, ensure_ascii=False)}\n\n"
            frame_queue = queue.Queue(maxsize=50)
            producer_thread = extract_frames_to_queue(video_path, frame_queue, max_queue_size=50)
            total_frames = 0
            fps = 0
            duration = 0
            resolution = ""
            video_info_received_once = False
            frame_infer_results = []
            processed_frames = 0
            total_frames_to_process = 0
            batch_cache = []
            batch_indices = []
            batch_arrays = []
            batch_count = 0
            total_infer_time = 0.0
            producer_finished = False
            last_batch_processed = False

            while connection_active and not error_occurred:
                if time.time() - last_heartbeat > _HEARTBEAT_INTERVAL:
                    yield send_heartbeat()
                    last_heartbeat = time.time()
                if producer_finished and frame_queue.empty() and len(batch_cache) == 0 and last_batch_processed:
                    print("âœ… æ‰€æœ‰å¸§å¤„ç†å®Œæˆ")
                    break
                try:
                    try:
                        item = frame_queue.get(timeout=0.5)
                        if item is None:
                            print("ğŸ“¨ æ”¶åˆ°ç»“æŸæ ‡è®°ï¼ŒæŠ½å¸§å®Œæˆ")
                            producer_finished = True
                            if batch_cache:
                                frame_results, infer_time, batch_count, total_infer_time = process_batch(
                                    batch_cache, batch_indices, batch_arrays,batch_count, total_infer_time, device_info)
                                for frame_result in frame_results:
                                    yield f"event: frame\ndata: {json.dumps(frame_result['data'], ensure_ascii=False)}\n\n"
                                    frame_infer_results.append(frame_result['scores'])
                                    yield send_heartbeat()
                                    last_heartbeat = time.time()
                                batch_cache = []
                                batch_indices = []
                                batch_arrays = []
                                last_batch_processed = True
                                if video_info_received_once and total_frames_to_process > 0:
                                    current_processed = len(frame_infer_results)
                                    progress = round((current_processed / total_frames_to_process) * 100, 1)
                                    current_fps = 0
                                    if total_infer_time > 0 and current_processed > 0:
                                        current_fps = current_processed / total_infer_time
                                    infer_progress_data = {
                                        'title': f'æ‰¹é‡æ¨ç†ä¸­...ï¼ˆå·²å¤„ç†{current_processed}å¸§ï¼Œæ€»{total_frames_to_process}å¸§ï¼Œæ‰¹æ¬¡{batch_count}ï¼‰',
                                        'current': current_processed,'total': total_frames_to_process,'progress': progress,
                                        'current_fps': round(current_fps, 2),'batch_size': _BATCH_SIZE}
                                    yield f"event: progress\ndata: {json.dumps(infer_progress_data, ensure_ascii=False)}\n\n"
                            else:
                                last_batch_processed = True
                            continue
                        if item[0] == 'video_info':
                            if not video_info_received_once:
                                total_frames, fps, duration, resolution = item[1], item[2], item[3], item[4]
                                total_frames_to_process = total_frames
                                video_info_received_once = True
                                print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯ï¼šæ€»å¸§æ•°{total_frames}ï¼Œå¸§ç‡{fps}ï¼Œæ—¶é•¿{duration:.2f}ç§’ï¼Œåˆ†è¾¨ç‡{resolution}")
                                progress_data = {'title': 'æŠ½å¸§ä¸­...ï¼ˆè¾¹æŠ½è¾¹æ¨ç†ï¼‰','current': 0,'total': total_frames,'progress': 0.0}
                                yield f"event: progress\ndata: {json.dumps(progress_data, ensure_ascii=False)}\n\n"
                            continue
                        if item[0] == 'error':
                            error_msg = f'æŠ½å¸§å¤±è´¥ï¼š{item[1]}'
                            yield f"event: error\ndata: {json.dumps({'message': error_msg}, ensure_ascii=False)}\n\n"
                            error_occurred = True
                            continue
                        if item[0] == 'frame_data':
                            frame_array, frame_idx = item[1], item[2]
                            batch_cache.append(frame_array)
                            batch_indices.append(frame_idx)
                            batch_arrays.append(frame_array.copy())
                            processed_frames += 1
                    except queue.Empty:
                        if producer_finished and len(batch_cache) == 0 and last_batch_processed:
                            break
                        continue
                    if len(batch_cache) >= _BATCH_SIZE:
                        frame_results, infer_time, batch_count, total_infer_time = process_batch(
                            batch_cache, batch_indices, batch_arrays,batch_count, total_infer_time, device_info)
                        for frame_result in frame_results:
                            yield f"event: frame\ndata: {json.dumps(frame_result['data'], ensure_ascii=False)}\n\n"
                            frame_infer_results.append(frame_result['scores'])
                            yield send_heartbeat()
                            last_heartbeat = time.time()
                        batch_cache = []
                        batch_indices = []
                        batch_arrays = []
                        if video_info_received_once and total_frames_to_process > 0:
                            current_processed = len(frame_infer_results)
                            progress = round((current_processed / total_frames_to_process) * 100, 1)
                            current_fps = 0
                            if total_infer_time > 0 and current_processed > 0:
                                current_fps = current_processed / total_infer_time
                            infer_progress_data = {
                                'title': f'æ‰¹é‡æ¨ç†ä¸­...ï¼ˆå·²å¤„ç†{current_processed}å¸§ï¼Œæ€»{total_frames_to_process}å¸§ï¼Œæ‰¹æ¬¡{batch_count}ï¼‰',
                                'current': current_processed,'total': total_frames_to_process,'progress': progress,
                                'current_fps': round(current_fps, 2),'batch_size': _BATCH_SIZE}
                            yield f"event: progress\ndata: {json.dumps(infer_progress_data, ensure_ascii=False)}\n\n"
                except Exception as e:
                    print(f"âš ï¸ æ¶ˆè´¹è€…å¾ªç¯å‡ºé”™ï¼š{str(e)}")
                    traceback.print_exc()
                    error_data = {'message': f'å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{str(e)}'}
                    yield f"event: error\ndata: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                    error_occurred = True
                    continue
            if producer_thread and producer_thread.is_alive():
                producer_thread.join(timeout=5.0)
            if error_occurred:
                print("âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
                return
            infer_end_time = time.time()
            infer_duration = round(infer_end_time - total_start_time, 2)
            if not frame_infer_results:
                error_msg = f"æ²¡æœ‰æœ‰æ•ˆå¸§å®Œæˆæ¨ç†"
                print(f"âŒ {error_msg}")
                yield f"event: error\ndata: {json.dumps({'message': error_msg}, ensure_ascii=False)}\n\n"
                return

            horror_scores = [f["horror"] for f in frame_infer_results if "horror" in f]
            violence_scores = [f["violence"] for f in frame_infer_results if "violence" in f]
            nsfw_scores = [f["nsfw"] for f in frame_infer_results if "nsfw" in f]
            risk_frames = sum(1 for f in frame_infer_results if f.get("is_risk", False))
            risk_ratio = risk_frames / len(frame_infer_results) if frame_infer_results else 0
            avg_horror = sum(horror_scores) / len(horror_scores) if horror_scores else 0
            avg_violence = sum(violence_scores) / len(violence_scores) if violence_scores else 0
            avg_nsfw = sum(nsfw_scores) / len(nsfw_scores) if nsfw_scores else 0

            avg_infer_time_per_frame = total_infer_time / len(frame_infer_results) * 1000 if frame_infer_results else 0
            infer_fps = len(frame_infer_results) / total_infer_time if total_infer_time > 0 else 0
            overall_fps = len(frame_infer_results) / infer_duration if infer_duration > 0 else 0
            avg_batch_size = len(frame_infer_results) / batch_count if batch_count > 0 else 0
            batch_efficiency = (avg_batch_size / _BATCH_SIZE * 100) if _BATCH_SIZE > 0 else 0

            risk_level = calculate_risk_level(avg_horror, avg_violence, avg_nsfw, risk_ratio)
            risk_score = calculate_risk_score(avg_horror, avg_violence, avg_nsfw, risk_ratio, risk_level)
            risk_desc = generate_risk_details(avg_horror, avg_violence, avg_nsfw)

            complete_data = {
                'risk_level': risk_level or "æœªçŸ¥",'risk_score': float(risk_score) if risk_score is not None else 0.0,
                'risk_desc': risk_desc or "åˆ†æå®Œæˆ",'video_resolution': resolution or "æœªçŸ¥",
                'video_duration': round(float(duration), 2) if duration else 0.0,'video_fps': round(float(fps), 2) if fps else 0.0,
                'total_frames': int(total_frames) if total_frames else len(frame_infer_results),'analyzed_frames': len(frame_infer_results),
                'risk_frames': int(risk_frames),'risk_ratio': round(float(risk_ratio), 4),
                'avg_horror': round(float(avg_horror), 2),'avg_violence': round(float(avg_violence), 2),
                'avg_nsfw': round(float(avg_nsfw), 3),'video_filename': video_info.get('filename', ''),
                'total_duration': round(float(infer_duration), 2),
                'avg_single_frame_duration': round(float(avg_infer_time_per_frame), 2) / 1000,
                'batch_performance': {
                    'batch_size': _BATCH_SIZE,'total_batches': int(batch_count),'avg_batch_size': round(float(avg_batch_size), 2),
                    'batch_efficiency_percent': round(float(batch_efficiency), 1),
                    'avg_inference_time_per_frame_ms': round(float(avg_infer_time_per_frame), 2),
                    'inference_fps': round(float(infer_fps), 2),'overall_fps': round(float(overall_fps), 2),
                    'total_inference_time_seconds': round(float(total_infer_time), 3),
                    'frames_per_second_overall': round(len(frame_infer_results) / infer_duration,2) if infer_duration > 0 else 0,
                    'inference_mode': 'batch',
                    'device': device_info['cuda_devices'][0]['name'] if device_info['cuda_available'] and device_info['cuda_devices'] else 'CPU'
                },'device_info': device_info
            }
            print("ğŸ“Š å‘é€åˆ†æå®Œæˆäº‹ä»¶...")
            try:
                complete_json = json.dumps(complete_data, ensure_ascii=False)
                # å¼ºåˆ¶ä¿å­˜åˆ†æç»“æœåˆ°è§†é¢‘ç¼“å­˜
                uploaded_videos[video_id]['analysis_result'] = complete_data
                save_video_cache()  # ç«‹å³æŒä¹…åŒ–
                yield f"event: complete\ndata: {complete_json}\n\n"
            except Exception as e:
                print(f"âŒ å‘é€å®Œæˆäº‹ä»¶å¤±è´¥: {e}")
                traceback.print_exc()
                error_data = {'message': f'å‘é€ç»“æœå¤±è´¥ï¼š{str(e)}'}
                yield f"event: error\ndata: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                return
            yield f"event: success\ndata: {json.dumps({'status': 'analysis_completed', 'message': 'åˆ†ææˆåŠŸå®Œæˆ'}, ensure_ascii=False)}\n\n"
        except Exception as e:
            print(f"âŒ SSEç”Ÿæˆå™¨å¼‚å¸¸: {str(e)}")
            traceback.print_exc()
            error_data = {'message': f'åˆ†æå¤±è´¥ï¼š{str(e)}'}
            yield f"event: error\ndata: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        finally:
            print("ğŸ”Œ SSEè¿æ¥å…³é—­")
    return Response(generate_sse(),mimetype='text/event-stream',headers={'Cache-Control': 'no-cache','Connection': 'keep-alive','X-Accel-Buffering': 'no','X-SSE-Ping-Interval': '2000'})

@app.route('/device-info', methods=['GET'])
def get_device_info():
    return jsonify({'success': True,'device_info': device_info,'performance_benchmark': performance_benchmark,'batch_size': _BATCH_SIZE})

@app.route('/submit-feedback', methods=['POST'])
def submit_feedback():
    try:
        data = request.get_json()
        if not data or not data.get("feedback_id"):
            return jsonify({"success": False, "message": "å‚æ•°é”™è¯¯ï¼Œç¼ºå°‘åé¦ˆID"}),400
        feedback_id = data["feedback_id"]
        feedback_file = os.path.join(FEEDBACK_DIR, f"{feedback_id}.json")
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(FEEDBACK_DIR, exist_ok=True)
        with open(feedback_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return jsonify({"success": True, "feedback_id": feedback_id})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"success": False, "message": f"æäº¤å¤±è´¥ï¼š{str(e)}"}),500

@app.route('/get-feedback-list', methods=['GET'])
def get_feedback_list():
    try:
        feedbacks = []
        if os.path.exists(FEEDBACK_DIR):
            for filename in os.listdir(FEEDBACK_DIR):
                if filename.endswith(".json"):
                    file_path = os.path.join(FEEDBACK_DIR, filename)
                    with open(file_path, "r", encoding="utf-8") as f:
                        fb = json.load(f)
                        feedbacks.append(fb)
        feedbacks.sort(key=lambda x: x['feedback_time'], reverse=True)
        return jsonify({"success": True, "feedbacks": feedbacks})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"success": False, "message": f"è·å–å¤±è´¥ï¼š{str(e)}"}),500

@app.route('/get-feedback', methods=['GET'])
def get_feedback():
    try:
        feedback_id = request.args.get('feedback_id')
        if not feedback_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘feedback_idå‚æ•°"}),400
        feedback_file = os.path.join(FEEDBACK_DIR, f"{feedback_id}.json")
        if not os.path.exists(feedback_file):
            return jsonify({"success": False, "message": "åé¦ˆè®°å½•ä¸å­˜åœ¨"}),404
        with open(feedback_file, "r", encoding="utf-8") as f:
            feedback = json.load(f)
        return jsonify({"success": True, "feedback": feedback})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"success": False, "message": f"è·å–å¤±è´¥ï¼š{str(e)}"}),500


@app.route('/get-re-audit-result', methods=['GET'])
def get_re_audit_result():
    try:
        video_id = request.args.get("video_id")
        if not video_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘video_idå‚æ•°"}),400
        if os.path.exists(FEEDBACK_DIR):
            for filename in os.listdir(FEEDBACK_DIR):
                if filename.endswith(".json"):
                    file_path = os.path.join(FEEDBACK_DIR, filename)
                    with open(file_path, "r", encoding="utf-8") as f:
                        feedback = json.load(f)
                        if feedback.get("video_id") == video_id and feedback.get("status") == "completed":
                            return jsonify({"success": True, "result": feedback})
        return jsonify({"success": False, "message": "æš‚æ— å®¡æ ¸ç»“æœ"})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"success": False, "message": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"}),500

# æ–°å¢ï¼šæ¥æ”¶å‰ç«¯åˆ†æç»“æœå¹¶æ›´æ–°ç¼“å­˜
@app.route('/update-video-analysis', methods=['POST'])
def update_video_analysis():
    try:
        data = request.get_json()
        video_id = data.get('video_id')
        analysis_result = data.get('analysis_result')

        # æ ¡éªŒå‚æ•°
        if not video_id or not analysis_result:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘video_idæˆ–analysis_resultå‚æ•°'})
        if video_id not in uploaded_videos:
            return jsonify({'success': False, 'message': 'è§†é¢‘IDä¸å­˜åœ¨'})

        # æ›´æ–°è§†é¢‘ç¼“å­˜çš„åˆ†æç»“æœ
        uploaded_videos[video_id]['analysis_result'] = analysis_result
        save_video_cache()  # æŒä¹…åŒ–ç¼“å­˜

        return jsonify({'success': True, 'message': 'åˆ†æç»“æœå·²åŒæ­¥åˆ°åç«¯'})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'åŒæ­¥å¤±è´¥ï¼š{str(e)}'})

@app.route('/static/<path:filename>')
def serve_static(filename):
    # ç›´æ¥ç”¨Flaskå†…ç½®çš„send_from_directoryï¼Œè‡ªåŠ¨å¤„ç†æ–‡ä»¶é‡Šæ”¾ï¼Œç¨³å®šæ— é”
    return send_from_directory(STATIC_DIR, filename, mimetype='video/mp4')
# ========== é¡µé¢è·¯ç”± ==========
@app.route('/feedback.html')
def feedback_page():
    return render_template('feedback.html')

@app.route('/audit.html')
def audit_page():
    return render_template('audit.html')

if __name__ == '__main__':
    initialize_system()
    print("âœ… å¯åŠ¨æˆåŠŸ === è®¿é—®åœ°å€è¯´æ˜ ===")
    print("âœ… è§†é¢‘åˆ†æä¸Šä¼ é¡µ: http://127.0.0.1:5000")
    print("âœ… äººå·¥å®¡æ ¸åå°: http://127.0.0.1:5000/audit.html")
    print("="*60)
    app.run(host='0.0.0.0',port=5000,debug=False,threaded=True,use_reloader=False,passthrough_errors=True)